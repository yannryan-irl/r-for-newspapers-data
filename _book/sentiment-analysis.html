<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>11 Sentiment analysis | A short guide to using British Library Newspaper Data, using R</title>
  <meta name="description" content="This is a handbook to help new and existing users find, process and analyse historical newspaper data, using the programming language R, and its IDE R-Studio" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="11 Sentiment analysis | A short guide to using British Library Newspaper Data, using R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a handbook to help new and existing users find, process and analyse historical newspaper data, using the programming language R, and its IDE R-Studio" />
  <meta name="github-repo" content="yannryanBL/r-for-news-data" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11 Sentiment analysis | A short guide to using British Library Newspaper Data, using R" />
  
  <meta name="twitter:description" content="This is a handbook to help new and existing users find, process and analyse historical newspaper data, using the programming language R, and its IDE R-Studio" />
  

<meta name="author" content="Yann Ryan" />


<meta name="date" content="2020-04-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="calculating-tf-idf-scores-with-tidytext.html"/>
<link rel="next" href="topic-modelling.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.3/leaflet.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface &amp; Acknowledgements</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#unlocking-the-past-with-newspaper-data"><i class="fa fa-check"></i><b>2.1</b> Unlocking the past with newspaper data</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#what-can-you-do-with-newspaper-data"><i class="fa fa-check"></i><b>2.2</b> What can you do with newspaper data?</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#goals"><i class="fa fa-check"></i><b>2.3</b> Goals</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#why-r"><i class="fa fa-check"></i><b>2.4</b> Why R?</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#getting-started"><i class="fa fa-check"></i><b>2.5</b> Getting started</a><ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#download-r-and-r-studio"><i class="fa fa-check"></i><b>2.5.1</b> Download R and R-Studio</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#who-is-the-guide-for"><i class="fa fa-check"></i><b>2.6</b> Who is the guide for?</a></li>
<li class="chapter" data-level="2.7" data-path="introduction.html"><a href="introduction.html#format-of-the-book"><i class="fa fa-check"></i><b>2.7</b> Format of the book</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html"><i class="fa fa-check"></i><b>3</b> UK Newspaper Data</a><ul>
<li class="chapter" data-level="3.1" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#intro-to-british-library-newspapers"><i class="fa fa-check"></i><b>3.1</b> Intro to British Library Newspapers</a></li>
<li class="chapter" data-level="3.2" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#burney-collection"><i class="fa fa-check"></i><b>3.2</b> Burney Collection</a></li>
<li class="chapter" data-level="3.3" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#jisc-newspaper-digitisation-projects"><i class="fa fa-check"></i><b>3.3</b> JISC Newspaper digitisation projects</a></li>
<li class="chapter" data-level="3.4" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#british-newspaper-archive"><i class="fa fa-check"></i><b>3.4</b> British Newspaper Archive</a></li>
<li class="chapter" data-level="3.5" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#british-library-openly-available-newspaper-data"><i class="fa fa-check"></i><b>3.5</b> British Library Openly available newspaper data</a></li>
<li class="chapter" data-level="3.6" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#what-access-do-you-need"><i class="fa fa-check"></i><b>3.6</b> What access do you need?</a><ul>
<li class="chapter" data-level="3.6.1" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#you-want-to-find-individual-articles"><i class="fa fa-check"></i><b>3.6.1</b> You want to find individual articles?</a></li>
<li class="chapter" data-level="3.6.2" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#you-want-to-do-text-mining-on-a-large-corpus"><i class="fa fa-check"></i><b>3.6.2</b> You want to do text mining on a large corpus</a></li>
<li class="chapter" data-level="3.6.3" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#you-want-to-do-text-mining-on-the-entire-digitised-collection"><i class="fa fa-check"></i><b>3.6.3</b> You want to do text mining on the entire digitised collection</a></li>
<li class="chapter" data-level="3.6.4" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#you-want-to-do-something-involving-the-images-such-as-computer-vision-techniques"><i class="fa fa-check"></i><b>3.6.4</b> You want to do something involving the images, such as computer vision techniques,</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html"><i class="fa fa-check"></i><b>4</b> OCR and its problems</a><ul>
<li class="chapter" data-level="4.1" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#introduction-1"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#what-is-it-like-in-bl-newspapers"><i class="fa fa-check"></i><b>4.2</b> What is it like in BL newspapers?</a></li>
<li class="chapter" data-level="4.3" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#ocr-report-on-the-first-two-batches-of-content-on-the-bl-open-repository"><i class="fa fa-check"></i><b>4.3</b> OCR report on the first two batches of content on the BL Open Repository</a></li>
<li class="chapter" data-level="4.4" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#extract-predicted-word-scores-from-the-alto-pages"><i class="fa fa-check"></i><b>4.4</b> Extract predicted word scores from the ALTO pages</a></li>
<li class="chapter" data-level="4.5" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#visualisations"><i class="fa fa-check"></i><b>4.5</b> Visualisations:</a><ul>
<li class="chapter" data-level="4.5.1" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#whats-in-the-data"><i class="fa fa-check"></i><b>4.5.1</b> What’s in the data?</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#highest-and-lowest-results"><i class="fa fa-check"></i><b>4.6</b> Highest and lowest results:</a></li>
<li class="chapter" data-level="4.7" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#page-by-page-ocr-visualisation"><i class="fa fa-check"></i><b>4.7</b> Page-by-page OCR visualisation</a></li>
<li class="chapter" data-level="4.8" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#microfilm-vs-print"><i class="fa fa-check"></i><b>4.8</b> Microfilm vs print:</a></li>
<li class="chapter" data-level="4.9" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#conclusions"><i class="fa fa-check"></i><b>4.9</b> Conclusions</a></li>
<li class="chapter" data-level="4.10" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#impact-on-analysis"><i class="fa fa-check"></i><b>4.10</b> Impact on analysis</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html"><i class="fa fa-check"></i><b>5</b> Quick introduction to R and the tidyverse</a><ul>
<li class="chapter" data-level="5.1" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#what-is-r-and-why-should-you-use-it"><i class="fa fa-check"></i><b>5.1</b> What is R and why should you use it?</a></li>
<li class="chapter" data-level="5.2" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#using-r"><i class="fa fa-check"></i><b>5.2</b> Using R</a><ul>
<li class="chapter" data-level="5.2.1" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#base-r-commands"><i class="fa fa-check"></i><b>5.2.1</b> Base R commands</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#tidyverse"><i class="fa fa-check"></i><b>5.3</b> Tidyverse</a><ul>
<li class="chapter" data-level="5.3.1" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#select-pull"><i class="fa fa-check"></i><b>5.3.1</b> select(), pull()</a></li>
<li class="chapter" data-level="5.3.2" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#group_by-tally-summarise"><i class="fa fa-check"></i><b>5.3.2</b> group_by(), tally(), summarise()</a></li>
<li class="chapter" data-level="5.3.3" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#filter"><i class="fa fa-check"></i><b>5.3.3</b> filter()</a></li>
<li class="chapter" data-level="5.3.4" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#sort-arrange-top_n"><i class="fa fa-check"></i><b>5.3.4</b> sort(), arrange(), top_n()</a></li>
<li class="chapter" data-level="5.3.5" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#left_join-inner_join-anti_join"><i class="fa fa-check"></i><b>5.3.5</b> left_join(), inner_join(), anti_join()</a></li>
<li class="chapter" data-level="5.3.6" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#piping"><i class="fa fa-check"></i><b>5.3.6</b> Piping</a></li>
<li class="chapter" data-level="5.3.7" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#plotting-using-ggplot"><i class="fa fa-check"></i><b>5.3.7</b> Plotting using ggplot()</a></li>
<li class="chapter" data-level="5.3.8" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#doing-this-with-newspaper-data"><i class="fa fa-check"></i><b>5.3.8</b> Doing this with newspaper data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><i class="fa fa-check"></i><b>6</b> Mapping with R: Geocode and Map the British Library’s Newspaper Collection</a><ul>
<li class="chapter" data-level="6.1" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#mapping-with-ggplot2-and-mapdata"><i class="fa fa-check"></i><b>6.1</b> Mapping with ggplot2 and mapdata</a><ul>
<li class="chapter" data-level="6.1.1" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#a-map-of-british-newspapers-by-city"><i class="fa fa-check"></i><b>6.1.1</b> A map of British Newspapers by City</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#drawing-a-background-map."><i class="fa fa-check"></i><b>6.2</b> Drawing a background map. `</a></li>
<li class="chapter" data-level="6.3" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#add-sized-points-by-coordinates"><i class="fa fa-check"></i><b>6.3</b> Add Sized Points By Coordinates</a><ul>
<li class="chapter" data-level="6.3.1" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#get-a-count-of-the-total-titles-for-each-city"><i class="fa fa-check"></i><b>6.3.1</b> Get a count of the total titles for each city</a></li>
<li class="chapter" data-level="6.3.2" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#get-hold-of-a-list-of-geocoordinates"><i class="fa fa-check"></i><b>6.3.2</b> Get hold of a list of geocoordinates</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#bringing-it-all-together"><i class="fa fa-check"></i><b>6.4</b> Bringing it all together</a></li>
<li class="chapter" data-level="6.5" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#drawing-a-newspaper-titles-choropleth-map-with-r-and-the-sf-package"><i class="fa fa-check"></i><b>6.5</b> Drawing a newspaper titles ‘Choropleth’ map with R and the sf package</a></li>
<li class="chapter" data-level="6.6" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#get-county-information-from-the-title-list"><i class="fa fa-check"></i><b>6.6</b> Get county information from the title list</a></li>
<li class="chapter" data-level="6.7" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#make-the-points-object-using-geom_sf"><i class="fa fa-check"></i><b>6.7</b> Make the points object using geom_sf()</a><ul>
<li class="chapter" data-level="6.7.1" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#download-shapefiles"><i class="fa fa-check"></i><b>6.7.1</b> Download shapefiles</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#transform-from-utm-to-latlong-using-st_transform"><i class="fa fa-check"></i><b>6.8</b> Transform from UTM to lat/long using st_transform()</a></li>
<li class="chapter" data-level="6.9" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#download-and-merge-the-title-list-with-a-set-of-coordinates."><i class="fa fa-check"></i><b>6.9</b> Download and merge the title list with a set of coordinates.</a></li>
<li class="chapter" data-level="6.10" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#using-st_join-to-connect-the-title-list-to-the-shapefile"><i class="fa fa-check"></i><b>6.10</b> Using st_join to connect the title list to the shapefile</a></li>
<li class="chapter" data-level="6.11" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#draw-using-ggplot2-and-geom_sf"><i class="fa fa-check"></i><b>6.11</b> Draw using ggplot2 and geom_sf()</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="download-and-unzip-newspaper-files-using-r.html"><a href="download-and-unzip-newspaper-files-using-r.html"><i class="fa fa-check"></i><b>7</b> Download and Unzip Newspaper Files Using R</a><ul>
<li class="chapter" data-level="7.1" data-path="download-and-unzip-newspaper-files-using-r.html"><a href="download-and-unzip-newspaper-files-using-r.html#download-a-set-of-newspaper-files-from-the-british-librarys-open-repository"><i class="fa fa-check"></i><b>7.1</b> Download a set of newspaper files from the British Library’s open repository</a></li>
<li class="chapter" data-level="7.2" data-path="download-and-unzip-newspaper-files-using-r.html"><a href="download-and-unzip-newspaper-files-using-r.html#folder-structure"><i class="fa fa-check"></i><b>7.2</b> Folder structure</a></li>
<li class="chapter" data-level="7.3" data-path="download-and-unzip-newspaper-files-using-r.html"><a href="download-and-unzip-newspaper-files-using-r.html#contruct-a-corpus"><i class="fa fa-check"></i><b>7.3</b> Contruct a Corpus</a></li>
<li class="chapter" data-level="7.4" data-path="download-and-unzip-newspaper-files-using-r.html"><a href="download-and-unzip-newspaper-files-using-r.html#bulk-extract-the-files-using-unzip-and-a-for-loop"><i class="fa fa-check"></i><b>7.4</b> Bulk extract the files using unzip() and a for() loop</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="extract-text.html"><a href="extract-text.html"><i class="fa fa-check"></i><b>8</b> Make a Text Corpus</a><ul>
<li class="chapter" data-level="8.1" data-path="extract-text.html"><a href="extract-text.html#where-is-this-data"><i class="fa fa-check"></i><b>8.1</b> Where is this data?</a></li>
<li class="chapter" data-level="8.2" data-path="extract-text.html"><a href="extract-text.html#folder-structure-1"><i class="fa fa-check"></i><b>8.2</b> Folder structure</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="term-frequencies.html"><a href="term-frequencies.html"><i class="fa fa-check"></i><b>9</b> Term Frequencies</a><ul>
<li class="chapter" data-level="9.1" data-path="term-frequencies.html"><a href="term-frequencies.html#load-the-news-dataframe-and-relevant-libraries"><i class="fa fa-check"></i><b>9.1</b> Load the news dataframe and relevant libraries</a></li>
<li class="chapter" data-level="9.2" data-path="term-frequencies.html"><a href="term-frequencies.html#tokenise-the-text-using-unnest_tokens"><i class="fa fa-check"></i><b>9.2</b> Tokenise the text using unnest_tokens()</a></li>
<li class="chapter" data-level="9.3" data-path="term-frequencies.html"><a href="term-frequencies.html#pre-process-to-clean-and-remove-stop-words"><i class="fa fa-check"></i><b>9.3</b> Pre-process to clean and remove stop words</a></li>
<li class="chapter" data-level="9.4" data-path="term-frequencies.html"><a href="term-frequencies.html#create-and-save-a-dataset-of-tokenised-text"><i class="fa fa-check"></i><b>9.4</b> Create and save a dataset of tokenised text</a></li>
<li class="chapter" data-level="9.5" data-path="term-frequencies.html"><a href="term-frequencies.html#count-the-tokens"><i class="fa fa-check"></i><b>9.5</b> Count the tokens</a><ul>
<li class="chapter" data-level="9.5.1" data-path="term-frequencies.html"><a href="term-frequencies.html#the-top-words-overall"><i class="fa fa-check"></i><b>9.5.1</b> The top words overall:</a></li>
<li class="chapter" data-level="9.5.2" data-path="term-frequencies.html"><a href="term-frequencies.html#the-top-five-words-for-each-day-in-the-dataset"><i class="fa fa-check"></i><b>9.5.2</b> The top five words for each day in the dataset:</a></li>
<li class="chapter" data-level="9.5.3" data-path="term-frequencies.html"><a href="term-frequencies.html#check-the-top-words-per-title-well-variant-titles-in-this-case"><i class="fa fa-check"></i><b>9.5.3</b> Check the top words per title (well, variant titles in this case):</a></li>
<li class="chapter" data-level="9.5.4" data-path="term-frequencies.html"><a href="term-frequencies.html#top-words-by-year"><i class="fa fa-check"></i><b>9.5.4</b> Top words by year</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="term-frequencies.html"><a href="term-frequencies.html#visualise-the-results"><i class="fa fa-check"></i><b>9.6</b> Visualise the Results</a><ul>
<li class="chapter" data-level="9.6.1" data-path="term-frequencies.html"><a href="term-frequencies.html#words-over-time"><i class="fa fa-check"></i><b>9.6.1</b> Words over time</a></li>
<li class="chapter" data-level="9.6.2" data-path="term-frequencies.html"><a href="term-frequencies.html#chart-several-words-over-time"><i class="fa fa-check"></i><b>9.6.2</b> Chart several words over time</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="term-frequencies.html"><a href="term-frequencies.html#further-reading"><i class="fa fa-check"></i><b>9.7</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="calculating-tf-idf-scores-with-tidytext.html"><a href="calculating-tf-idf-scores-with-tidytext.html"><i class="fa fa-check"></i><b>10</b> Calculating tf-idf Scores with Tidytext</a></li>
<li class="chapter" data-level="11" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html"><i class="fa fa-check"></i><b>11</b> Sentiment analysis</a><ul>
<li class="chapter" data-level="11.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#install-and-load-relevant-packages"><i class="fa fa-check"></i><b>11.1</b> Install and load relevant packages</a></li>
<li class="chapter" data-level="11.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#fetch-sentiment-data"><i class="fa fa-check"></i><b>11.2</b> Fetch sentiment data</a><ul>
<li class="chapter" data-level="11.2.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#afinn-dataset"><i class="fa fa-check"></i><b>11.2.1</b> Afinn dataset</a></li>
<li class="chapter" data-level="11.2.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#bing-dataset"><i class="fa fa-check"></i><b>11.2.2</b> Bing dataset</a></li>
<li class="chapter" data-level="11.2.3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#loughran-dataset"><i class="fa fa-check"></i><b>11.2.3</b> Loughran dataset</a></li>
<li class="chapter" data-level="11.2.4" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#nrc-dataset"><i class="fa fa-check"></i><b>11.2.4</b> NRC dataset</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#load-the-tokenised-news-sample"><i class="fa fa-check"></i><b>11.3</b> Load the tokenised news sample</a></li>
<li class="chapter" data-level="11.4" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#charting-changes-in-sentiment-over-time"><i class="fa fa-check"></i><b>11.4</b> Charting Changes in Sentiment Over Time</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="topic-modelling.html"><a href="topic-modelling.html"><i class="fa fa-check"></i><b>12</b> Topic modelling</a><ul>
<li class="chapter" data-level="12.1" data-path="topic-modelling.html"><a href="topic-modelling.html#topic-modelling-with-the-library-topicmodels"><i class="fa fa-check"></i><b>12.1</b> Topic modelling with the library ‘topicmodels’</a></li>
<li class="chapter" data-level="12.2" data-path="topic-modelling.html"><a href="topic-modelling.html#load-the-tokenised-dataframe"><i class="fa fa-check"></i><b>12.2</b> Load the tokenised dataframe</a></li>
<li class="chapter" data-level="12.3" data-path="topic-modelling.html"><a href="topic-modelling.html#create-a-dataframe-of-word-counts-with-tf_idf-scores"><i class="fa fa-check"></i><b>12.3</b> Create a dataframe of word counts with tf_idf scores</a></li>
<li class="chapter" data-level="12.4" data-path="topic-modelling.html"><a href="topic-modelling.html#make-a-document-term-matrix"><i class="fa fa-check"></i><b>12.4</b> Make a ‘document term matrix’</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html"><i class="fa fa-check"></i><b>13</b> Detecting text reuse in newspaper articles.</a><ul>
<li class="chapter" data-level="13.1" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#turn-the-newspaper-sample-into-a-bunch-of-text-documents-one-per-article"><i class="fa fa-check"></i><b>13.1</b> Turn the newspaper sample into a bunch of text documents, one per article</a><ul>
<li class="chapter" data-level="13.1.1" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#load-the-dataframe-and-preprocess"><i class="fa fa-check"></i><b>13.1.1</b> Load the dataframe and preprocess</a></li>
<li class="chapter" data-level="13.1.2" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#make-a-text-file-from-each-article"><i class="fa fa-check"></i><b>13.1.2</b> Make a text file from each article</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#load-the-files-as-a-textreusecorpus"><i class="fa fa-check"></i><b>13.2</b> Load the files as a TextReuseCorpus</a><ul>
<li class="chapter" data-level="13.2.1" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#generate-a-minhash"><i class="fa fa-check"></i><b>13.2.1</b> Generate a minhash</a></li>
<li class="chapter" data-level="13.2.2" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#create-the-textreusecorpus"><i class="fa fa-check"></i><b>13.2.2</b> Create the TextReuseCorpus</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#further-reading-1"><i class="fa fa-check"></i><b>13.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="further-reading-2.html"><a href="further-reading-2.html"><i class="fa fa-check"></i><b>14</b> Further reading</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A short guide to using British Library Newspaper Data, using R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sentiment-analysis" class="section level1">
<h1><span class="header-section-number">11</span> Sentiment analysis</h1>
<p>A surprisingly easy text mining task, once your documents have been turned into a tokenised dataframe, is sentiment analysis. Sentiment analysis is the name for a range of techniques which attempt to measure emotion in a text.</p>
<p>There are lots of ways of doing this, which become more and more sophisticated. One fairly simple but robust method is to take a dataset of words with corresponding sentiment scores (this could be a simple negative or positive score, or a score for each of a range of emotions). Then you join these scores to your tokenised dataframe, and count them.</p>
<p>The tricky bit is working out what it all means: You could argue that it’s reductive to reduce a text to the sum of its positive and negative scores for each word - this is obviously not the way that language works. Also, if you’re summing the scores, you need to think about the unit you’re summarising by. Can you measure the emotions of a newspaper? or does it have to be per article? And of <em>course</em> it goes without saying that this was created by modern readers for use on modern text.</p>
<p>Despite these questions, it can throw up some interesting patterns. Perhaps, if used correctly, one might be able to understand something of the way an event was reported, though it may not actually help with the ‘sentiment’ of the article, but rather reporting style or focus. I think with the right use, sentiment shows some promise when specifically applied to newspaper data, but thinking of it as sentiment may be a fool’s errand: it tells us something about the focus or style of an article, and over time and in bulk, something of a newspaper’s style or change in style.</p>
<p>The <em>tidytext</em> library has a few built-in sentiment score datasets (or lexicons). To load them first install the textdata and tidytext packages, if they’re not installed already (using <code>install.packages()</code>)</p>
<div id="install-and-load-relevant-packages" class="section level2">
<h2><span class="header-section-number">11.1</span> Install and load relevant packages</h2>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb167-1" data-line-number="1"><span class="kw">library</span>(textdata)</a>
<a class="sourceLine" id="cb167-2" data-line-number="2"><span class="kw">library</span>(tidytext)</a>
<a class="sourceLine" id="cb167-3" data-line-number="3"><span class="kw">library</span>(tidyverse)</a></code></pre></div>
</div>
<div id="fetch-sentiment-data" class="section level2">
<h2><span class="header-section-number">11.2</span> Fetch sentiment data</h2>
<p>Next use a function in the tidytext library called <code>get_sentiments()</code>. All this does is retrieve a dataset of sentiment scores and store them as a dataframe.</p>
<p>There are four to choose from - I’ll quickly explain each one.</p>
<div id="afinn-dataset" class="section level3">
<h3><span class="header-section-number">11.2.1</span> Afinn dataset</h3>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb168-1" data-line-number="1">afinnsentiments =<span class="st"> </span><span class="kw">get_sentiments</span>(<span class="st">&#39;afinn&#39;</span>)</a>
<a class="sourceLine" id="cb168-2" data-line-number="2"></a>
<a class="sourceLine" id="cb168-3" data-line-number="3"><span class="kw">head</span>(afinnsentiments,<span class="dv">10</span>)</a></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##    word       value
##    &lt;chr&gt;      &lt;dbl&gt;
##  1 abandon       -2
##  2 abandoned     -2
##  3 abandons      -2
##  4 abducted      -2
##  5 abduction     -2
##  6 abductions    -2
##  7 abhor         -3
##  8 abhorred      -3
##  9 abhorrent     -3
## 10 abhors        -3</code></pre>
<p>The Afinn dataset has two colums: words in one column, and a value between -5 and +5 in the other. The value is a numeric score of the word’s perceived positivity or negativity. More information is available on the <a href="https://github.com/fnielsen/afinn">official project GitHub page</a></p>
</div>
<div id="bing-dataset" class="section level3">
<h3><span class="header-section-number">11.2.2</span> Bing dataset</h3>
<p>The second, the Bing dataset, was compiled by the researchers Minqing Hu and Bing Liu. It is <em>also</em> a list of words, with each classified as either positive or negative.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb170-1" data-line-number="1">bingsentiments =<span class="st"> </span><span class="kw">get_sentiments</span>(<span class="st">&#39;bing&#39;</span>)</a>
<a class="sourceLine" id="cb170-2" data-line-number="2"></a>
<a class="sourceLine" id="cb170-3" data-line-number="3"><span class="kw">head</span>(bingsentiments,<span class="dv">10</span>)</a></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##    word        sentiment
##    &lt;chr&gt;       &lt;chr&gt;    
##  1 2-faces     negative 
##  2 abnormal    negative 
##  3 abolish     negative 
##  4 abominable  negative 
##  5 abominably  negative 
##  6 abominate   negative 
##  7 abomination negative 
##  8 abort       negative 
##  9 aborted     negative 
## 10 aborts      negative</code></pre>
</div>
<div id="loughran-dataset" class="section level3">
<h3><span class="header-section-number">11.2.3</span> Loughran dataset</h3>
<p>I’ve never used it, but it’s clearly similar to the Bing dataset, with a column of words and a classification of either negative or positive. More information and the original files can be found on the <a href="https://sraf.nd.edu/textual-analysis/resources/">creator’s website</a></p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb172-1" data-line-number="1">loughransentiments =<span class="st"> </span><span class="kw">get_sentiments</span>(<span class="st">&#39;loughran&#39;</span>)</a>
<a class="sourceLine" id="cb172-2" data-line-number="2"></a>
<a class="sourceLine" id="cb172-3" data-line-number="3"><span class="kw">head</span>(loughransentiments,<span class="dv">10</span>)</a></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##    word         sentiment
##    &lt;chr&gt;        &lt;chr&gt;    
##  1 abandon      negative 
##  2 abandoned    negative 
##  3 abandoning   negative 
##  4 abandonment  negative 
##  5 abandonments negative 
##  6 abandons     negative 
##  7 abdicated    negative 
##  8 abdicates    negative 
##  9 abdicating   negative 
## 10 abdication   negative</code></pre>
</div>
<div id="nrc-dataset" class="section level3">
<h3><span class="header-section-number">11.2.4</span> NRC dataset</h3>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb174-1" data-line-number="1">nrcsentiments =<span class="st"> </span><span class="kw">get_sentiments</span>(<span class="st">&#39;nrc&#39;</span>)</a>
<a class="sourceLine" id="cb174-2" data-line-number="2"></a>
<a class="sourceLine" id="cb174-3" data-line-number="3"><span class="kw">head</span>(nrcsentiments,<span class="dv">10</span>)</a></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##    word        sentiment
##    &lt;chr&gt;       &lt;chr&gt;    
##  1 abacus      trust    
##  2 abandon     fear     
##  3 abandon     negative 
##  4 abandon     sadness  
##  5 abandoned   anger    
##  6 abandoned   fear     
##  7 abandoned   negative 
##  8 abandoned   sadness  
##  9 abandonment anger    
## 10 abandonment fear</code></pre>
<blockquote>
<p>The NRC Emotion Lexicon is a list of English words and their associations with eight basic emotions (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and two sentiments (negative and positive). The annotations were manually done by crowdsourcing.</p>
</blockquote>
<p>(<a href="https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm" class="uri">https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm</a>)</p>
<p>The NRC dataset is a bit different to the other ones. This time, there’s a list of words, and an emotion associated with that word. A word can have multiple entries, with different emotions attached to them.</p>
</div>
</div>
<div id="load-the-tokenised-news-sample" class="section level2">
<h2><span class="header-section-number">11.3</span> Load the tokenised news sample</h2>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb176-1" data-line-number="1"><span class="kw">load</span>(<span class="st">&#39;tokenised_news_sample&#39;</span>)</a></code></pre></div>
<p>This has two colums, ‘word’ and ‘value’. <code>inner_join()</code> will allow you to merge this with the tokenised dataframe.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb177-1" data-line-number="1">tokenised_news_sample <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">inner_join</span>(afinnsentiments)</a></code></pre></div>
<pre><code>## Joining, by = &quot;word&quot;</code></pre>
<pre><code>## # A tibble: 2,056,429 x 8
##    article_code art   title   year  date  full_date  word     value
##           &lt;int&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;date&gt;     &lt;chr&gt;    &lt;dbl&gt;
##  1           11 0011  0002083 1853  0924  1853-09-24 favor        2
##  2           12 0012  0002083 1853  0924  1853-09-24 blind       -1
##  3           16 0016  0002083 1853  0924  1853-09-24 worth        2
##  4           16 0016  0002083 1853  0924  1853-09-24 ban         -2
##  5           16 0016  0002083 1853  0924  1853-09-24 benefit      2
##  6           28 0028  0002083 1853  0924  1853-09-24 united       1
##  7           31 0031  0002083 1853  0924  1853-09-24 bankrupt    -3
##  8           36 0036  0002083 1853  0924  1853-09-24 mad         -3
##  9           40 0040  0002083 1853  0924  1853-09-24 resolve      2
## 10           40 0040  0002083 1853  0924  1853-09-24 ass         -4
## # … with 2,056,419 more rows</code></pre>
<p>Now we have a list of all the words, one per line, which occurred in the afinn list, and their individual score. To make this in any way useful, we need to summarise the scores. The article seems by far the most logical start. We can get the average score for each article, which will tell us whether the article contained more positive or negative words. For this we use <code>tally()</code> and <code>mean()</code></p>
<p>I’m also using add_tally() to filter out only articles which contain at least 20 of these words from the lexicon, because I think it will make the score more meaningful.</p>
<p>Let’s look at the most ‘positive’ article</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb180-1" data-line-number="1">tokenised_news_sample <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb180-2" data-line-number="2"><span class="st">  </span><span class="kw">inner_join</span>(afinnsentiments) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb180-3" data-line-number="3"><span class="st">  </span><span class="kw">group_by</span>(article_code) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb180-4" data-line-number="4"><span class="st">  </span><span class="kw">add_tally</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb180-5" data-line-number="5"><span class="st">  </span><span class="kw">filter</span>(n<span class="op">&gt;</span><span class="dv">20</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb180-6" data-line-number="6"><span class="st">  </span><span class="kw">tally</span>(<span class="kw">mean</span>(value)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb180-7" data-line-number="7"><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n))</a></code></pre></div>
<pre><code>## Joining, by = &quot;word&quot;</code></pre>
<pre><code>## # A tibble: 26,356 x 2
##    article_code     n
##           &lt;int&gt; &lt;dbl&gt;
##  1        31489  2.7 
##  2        33257  2.64
##  3        53197  2.61
##  4        17309  2.56
##  5        53655  2.52
##  6        54015  2.52
##  7        32873  2.52
##  8         7114  2.5 
##  9        52521  2.48
## 10         6675  2.48
## # … with 26,346 more rows</code></pre>
</div>
<div id="charting-changes-in-sentiment-over-time" class="section level2">
<h2><span class="header-section-number">11.4</span> Charting Changes in Sentiment Over Time</h2>
<p>Sentiment analysis should be uesd with caution, but it’s potentially a useful tool, particularly to look at changes over time, or differences between newspapers or authors. We can plot the average of all the average article scores. If we had them, this could be segmented by title.</p>
<p>Here I’ve charted all the sentiments found in the sample dataframe - but note that because the sample is so sparse and uneven, I’ve not spaced the dates temporally, but rather just one after another.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb183-1" data-line-number="1">tokenised_news_sample <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb183-2" data-line-number="2"><span class="st">  </span><span class="kw">inner_join</span>(afinnsentiments) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb183-3" data-line-number="3"><span class="st">  </span><span class="kw">group_by</span>(full_date,article_code) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb183-4" data-line-number="4"><span class="st">  </span><span class="kw">add_tally</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb183-5" data-line-number="5"><span class="st">  </span><span class="kw">filter</span>(n<span class="op">&gt;</span><span class="dv">20</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb183-6" data-line-number="6"><span class="st">  </span><span class="kw">tally</span>(<span class="kw">mean</span>(value)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb183-7" data-line-number="7"><span class="st">  </span><span class="kw">group_by</span>(full_date) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb183-8" data-line-number="8"><span class="st">  </span><span class="kw">tally</span>(<span class="kw">mean</span>(n)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb183-9" data-line-number="9"><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb183-10" data-line-number="10"><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb183-11" data-line-number="11"><span class="st">  </span><span class="kw">geom_col</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.character</span>(full_date), <span class="dt">y =</span> n)) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">45</span>, <span class="dt">hjust =</span> <span class="dv">1</span>, <span class="dt">vjust =</span> <span class="dv">1</span>))</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-161"></span>
<img src="_main_files/figure-html/unnamed-chunk-161-1.png" alt="Sentiment Over Time" width="768" />
<p class="caption">
Figure 11.1: Sentiment Over Time
</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="calculating-tf-idf-scores-with-tidytext.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="topic-modelling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
