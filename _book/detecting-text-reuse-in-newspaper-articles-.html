<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13 Detecting text reuse in newspaper articles. | A short guide to using British Library Newspaper Data, using R</title>
  <meta name="description" content="This is a handbook to help new and existing users find, process and analyse historical newspaper data, using the programming language R, and its IDE R-Studio" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="13 Detecting text reuse in newspaper articles. | A short guide to using British Library Newspaper Data, using R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a handbook to help new and existing users find, process and analyse historical newspaper data, using the programming language R, and its IDE R-Studio" />
  <meta name="github-repo" content="yannryanBL/r-for-news-data" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13 Detecting text reuse in newspaper articles. | A short guide to using British Library Newspaper Data, using R" />
  
  <meta name="twitter:description" content="This is a handbook to help new and existing users find, process and analyse historical newspaper data, using the programming language R, and its IDE R-Studio" />
  

<meta name="author" content="Yann Ryan" />


<meta name="date" content="2020-04-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="topic-modelling.html"/>
<link rel="next" href="further-reading-2.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.3/leaflet.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface &amp; Acknowledgements</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#unlocking-the-past-with-newspaper-data"><i class="fa fa-check"></i><b>2.1</b> Unlocking the past with newspaper data</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#what-can-you-do-with-newspaper-data"><i class="fa fa-check"></i><b>2.2</b> What can you do with newspaper data?</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#goals"><i class="fa fa-check"></i><b>2.3</b> Goals</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#why-r"><i class="fa fa-check"></i><b>2.4</b> Why R?</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#getting-started"><i class="fa fa-check"></i><b>2.5</b> Getting started</a><ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#download-r-and-r-studio"><i class="fa fa-check"></i><b>2.5.1</b> Download R and R-Studio</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#who-is-the-guide-for"><i class="fa fa-check"></i><b>2.6</b> Who is the guide for?</a></li>
<li class="chapter" data-level="2.7" data-path="introduction.html"><a href="introduction.html#format-of-the-book"><i class="fa fa-check"></i><b>2.7</b> Format of the book</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html"><i class="fa fa-check"></i><b>3</b> UK Newspaper Data</a><ul>
<li class="chapter" data-level="3.1" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#intro-to-british-library-newspapers"><i class="fa fa-check"></i><b>3.1</b> Intro to British Library Newspapers</a></li>
<li class="chapter" data-level="3.2" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#burney-collection"><i class="fa fa-check"></i><b>3.2</b> Burney Collection</a></li>
<li class="chapter" data-level="3.3" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#jisc-newspaper-digitisation-projects"><i class="fa fa-check"></i><b>3.3</b> JISC Newspaper digitisation projects</a></li>
<li class="chapter" data-level="3.4" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#british-newspaper-archive"><i class="fa fa-check"></i><b>3.4</b> British Newspaper Archive</a></li>
<li class="chapter" data-level="3.5" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#british-library-openly-available-newspaper-data"><i class="fa fa-check"></i><b>3.5</b> British Library Openly available newspaper data</a></li>
<li class="chapter" data-level="3.6" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#what-access-do-you-need"><i class="fa fa-check"></i><b>3.6</b> What access do you need?</a><ul>
<li class="chapter" data-level="3.6.1" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#you-want-to-find-individual-articles"><i class="fa fa-check"></i><b>3.6.1</b> You want to find individual articles?</a></li>
<li class="chapter" data-level="3.6.2" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#you-want-to-do-text-mining-on-a-large-corpus"><i class="fa fa-check"></i><b>3.6.2</b> You want to do text mining on a large corpus</a></li>
<li class="chapter" data-level="3.6.3" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#you-want-to-do-text-mining-on-the-entire-digitised-collection"><i class="fa fa-check"></i><b>3.6.3</b> You want to do text mining on the entire digitised collection</a></li>
<li class="chapter" data-level="3.6.4" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#you-want-to-do-something-involving-the-images-such-as-computer-vision-techniques"><i class="fa fa-check"></i><b>3.6.4</b> You want to do something involving the images, such as computer vision techniques,</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html"><i class="fa fa-check"></i><b>4</b> OCR and its problems</a><ul>
<li class="chapter" data-level="4.1" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#introduction-1"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#what-is-it-like-in-bl-newspapers"><i class="fa fa-check"></i><b>4.2</b> What is it like in BL newspapers?</a></li>
<li class="chapter" data-level="4.3" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#ocr-report-on-the-first-two-batches-of-content-on-the-bl-open-repository"><i class="fa fa-check"></i><b>4.3</b> OCR report on the first two batches of content on the BL Open Repository</a></li>
<li class="chapter" data-level="4.4" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#extract-predicted-word-scores-from-the-alto-pages"><i class="fa fa-check"></i><b>4.4</b> Extract predicted word scores from the ALTO pages</a></li>
<li class="chapter" data-level="4.5" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#visualisations"><i class="fa fa-check"></i><b>4.5</b> Visualisations:</a><ul>
<li class="chapter" data-level="4.5.1" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#whats-in-the-data"><i class="fa fa-check"></i><b>4.5.1</b> What’s in the data?</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#highest-and-lowest-results"><i class="fa fa-check"></i><b>4.6</b> Highest and lowest results:</a></li>
<li class="chapter" data-level="4.7" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#page-by-page-ocr-visualisation"><i class="fa fa-check"></i><b>4.7</b> Page-by-page OCR visualisation</a></li>
<li class="chapter" data-level="4.8" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#microfilm-vs-print"><i class="fa fa-check"></i><b>4.8</b> Microfilm vs print:</a></li>
<li class="chapter" data-level="4.9" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#conclusions"><i class="fa fa-check"></i><b>4.9</b> Conclusions</a></li>
<li class="chapter" data-level="4.10" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#impact-on-analysis"><i class="fa fa-check"></i><b>4.10</b> Impact on analysis</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html"><i class="fa fa-check"></i><b>5</b> Quick introduction to R and the tidyverse</a><ul>
<li class="chapter" data-level="5.1" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#what-is-r-and-why-should-you-use-it"><i class="fa fa-check"></i><b>5.1</b> What is R and why should you use it?</a></li>
<li class="chapter" data-level="5.2" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#using-r"><i class="fa fa-check"></i><b>5.2</b> Using R</a><ul>
<li class="chapter" data-level="5.2.1" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#base-r-commands"><i class="fa fa-check"></i><b>5.2.1</b> Base R commands</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#tidyverse"><i class="fa fa-check"></i><b>5.3</b> Tidyverse</a><ul>
<li class="chapter" data-level="5.3.1" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#select-pull"><i class="fa fa-check"></i><b>5.3.1</b> select(), pull()</a></li>
<li class="chapter" data-level="5.3.2" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#group_by-tally-summarise"><i class="fa fa-check"></i><b>5.3.2</b> group_by(), tally(), summarise()</a></li>
<li class="chapter" data-level="5.3.3" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#filter"><i class="fa fa-check"></i><b>5.3.3</b> filter()</a></li>
<li class="chapter" data-level="5.3.4" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#sort-arrange-top_n"><i class="fa fa-check"></i><b>5.3.4</b> sort(), arrange(), top_n()</a></li>
<li class="chapter" data-level="5.3.5" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#left_join-inner_join-anti_join"><i class="fa fa-check"></i><b>5.3.5</b> left_join(), inner_join(), anti_join()</a></li>
<li class="chapter" data-level="5.3.6" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#piping"><i class="fa fa-check"></i><b>5.3.6</b> Piping</a></li>
<li class="chapter" data-level="5.3.7" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#plotting-using-ggplot"><i class="fa fa-check"></i><b>5.3.7</b> Plotting using ggplot()</a></li>
<li class="chapter" data-level="5.3.8" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#doing-this-with-newspaper-data"><i class="fa fa-check"></i><b>5.3.8</b> Doing this with newspaper data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><i class="fa fa-check"></i><b>6</b> Mapping with R: Geocode and Map the British Library’s Newspaper Collection</a><ul>
<li class="chapter" data-level="6.1" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#mapping-with-ggplot2-and-mapdata"><i class="fa fa-check"></i><b>6.1</b> Mapping with ggplot2 and mapdata</a><ul>
<li class="chapter" data-level="6.1.1" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#a-map-of-british-newspapers-by-city"><i class="fa fa-check"></i><b>6.1.1</b> A map of British Newspapers by City</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#drawing-a-background-map."><i class="fa fa-check"></i><b>6.2</b> Drawing a background map. `</a></li>
<li class="chapter" data-level="6.3" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#add-sized-points-by-coordinates"><i class="fa fa-check"></i><b>6.3</b> Add Sized Points By Coordinates</a><ul>
<li class="chapter" data-level="6.3.1" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#get-a-count-of-the-total-titles-for-each-city"><i class="fa fa-check"></i><b>6.3.1</b> Get a count of the total titles for each city</a></li>
<li class="chapter" data-level="6.3.2" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#get-hold-of-a-list-of-geocoordinates"><i class="fa fa-check"></i><b>6.3.2</b> Get hold of a list of geocoordinates</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#bringing-it-all-together"><i class="fa fa-check"></i><b>6.4</b> Bringing it all together</a></li>
<li class="chapter" data-level="6.5" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#drawing-a-newspaper-titles-choropleth-map-with-r-and-the-sf-package"><i class="fa fa-check"></i><b>6.5</b> Drawing a newspaper titles ‘Choropleth’ map with R and the sf package</a></li>
<li class="chapter" data-level="6.6" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#get-county-information-from-the-title-list"><i class="fa fa-check"></i><b>6.6</b> Get county information from the title list</a></li>
<li class="chapter" data-level="6.7" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#make-the-points-object-using-geom_sf"><i class="fa fa-check"></i><b>6.7</b> Make the points object using geom_sf()</a><ul>
<li class="chapter" data-level="6.7.1" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#download-shapefiles"><i class="fa fa-check"></i><b>6.7.1</b> Download shapefiles</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#transform-from-utm-to-latlong-using-st_transform"><i class="fa fa-check"></i><b>6.8</b> Transform from UTM to lat/long using st_transform()</a></li>
<li class="chapter" data-level="6.9" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#download-and-merge-the-title-list-with-a-set-of-coordinates."><i class="fa fa-check"></i><b>6.9</b> Download and merge the title list with a set of coordinates.</a></li>
<li class="chapter" data-level="6.10" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#using-st_join-to-connect-the-title-list-to-the-shapefile"><i class="fa fa-check"></i><b>6.10</b> Using st_join to connect the title list to the shapefile</a></li>
<li class="chapter" data-level="6.11" data-path="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html"><a href="mapping-with-r-geocode-and-map-the-british-librarys-newspaper-collection.html#draw-using-ggplot2-and-geom_sf"><i class="fa fa-check"></i><b>6.11</b> Draw using ggplot2 and geom_sf()</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="download-and-unzip-newspaper-files-using-r.html"><a href="download-and-unzip-newspaper-files-using-r.html"><i class="fa fa-check"></i><b>7</b> Download and Unzip Newspaper Files Using R</a><ul>
<li class="chapter" data-level="7.1" data-path="download-and-unzip-newspaper-files-using-r.html"><a href="download-and-unzip-newspaper-files-using-r.html#download-a-set-of-newspaper-files-from-the-british-librarys-open-repository"><i class="fa fa-check"></i><b>7.1</b> Download a set of newspaper files from the British Library’s open repository</a></li>
<li class="chapter" data-level="7.2" data-path="download-and-unzip-newspaper-files-using-r.html"><a href="download-and-unzip-newspaper-files-using-r.html#folder-structure"><i class="fa fa-check"></i><b>7.2</b> Folder structure</a></li>
<li class="chapter" data-level="7.3" data-path="download-and-unzip-newspaper-files-using-r.html"><a href="download-and-unzip-newspaper-files-using-r.html#contruct-a-corpus"><i class="fa fa-check"></i><b>7.3</b> Contruct a Corpus</a></li>
<li class="chapter" data-level="7.4" data-path="download-and-unzip-newspaper-files-using-r.html"><a href="download-and-unzip-newspaper-files-using-r.html#bulk-extract-the-files-using-unzip-and-a-for-loop"><i class="fa fa-check"></i><b>7.4</b> Bulk extract the files using unzip() and a for() loop</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="extract-text.html"><a href="extract-text.html"><i class="fa fa-check"></i><b>8</b> Make a Text Corpus</a><ul>
<li class="chapter" data-level="8.1" data-path="extract-text.html"><a href="extract-text.html#where-is-this-data"><i class="fa fa-check"></i><b>8.1</b> Where is this data?</a></li>
<li class="chapter" data-level="8.2" data-path="extract-text.html"><a href="extract-text.html#folder-structure-1"><i class="fa fa-check"></i><b>8.2</b> Folder structure</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="term-frequencies.html"><a href="term-frequencies.html"><i class="fa fa-check"></i><b>9</b> Term Frequencies</a><ul>
<li class="chapter" data-level="9.1" data-path="term-frequencies.html"><a href="term-frequencies.html#load-the-news-dataframe-and-relevant-libraries"><i class="fa fa-check"></i><b>9.1</b> Load the news dataframe and relevant libraries</a></li>
<li class="chapter" data-level="9.2" data-path="term-frequencies.html"><a href="term-frequencies.html#tokenise-the-text-using-unnest_tokens"><i class="fa fa-check"></i><b>9.2</b> Tokenise the text using unnest_tokens()</a></li>
<li class="chapter" data-level="9.3" data-path="term-frequencies.html"><a href="term-frequencies.html#pre-process-to-clean-and-remove-stop-words"><i class="fa fa-check"></i><b>9.3</b> Pre-process to clean and remove stop words</a></li>
<li class="chapter" data-level="9.4" data-path="term-frequencies.html"><a href="term-frequencies.html#create-and-save-a-dataset-of-tokenised-text"><i class="fa fa-check"></i><b>9.4</b> Create and save a dataset of tokenised text</a></li>
<li class="chapter" data-level="9.5" data-path="term-frequencies.html"><a href="term-frequencies.html#count-the-tokens"><i class="fa fa-check"></i><b>9.5</b> Count the tokens</a><ul>
<li class="chapter" data-level="9.5.1" data-path="term-frequencies.html"><a href="term-frequencies.html#the-top-words-overall"><i class="fa fa-check"></i><b>9.5.1</b> The top words overall:</a></li>
<li class="chapter" data-level="9.5.2" data-path="term-frequencies.html"><a href="term-frequencies.html#the-top-five-words-for-each-day-in-the-dataset"><i class="fa fa-check"></i><b>9.5.2</b> The top five words for each day in the dataset:</a></li>
<li class="chapter" data-level="9.5.3" data-path="term-frequencies.html"><a href="term-frequencies.html#check-the-top-words-per-title-well-variant-titles-in-this-case"><i class="fa fa-check"></i><b>9.5.3</b> Check the top words per title (well, variant titles in this case):</a></li>
<li class="chapter" data-level="9.5.4" data-path="term-frequencies.html"><a href="term-frequencies.html#top-words-by-year"><i class="fa fa-check"></i><b>9.5.4</b> Top words by year</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="term-frequencies.html"><a href="term-frequencies.html#visualise-the-results"><i class="fa fa-check"></i><b>9.6</b> Visualise the Results</a><ul>
<li class="chapter" data-level="9.6.1" data-path="term-frequencies.html"><a href="term-frequencies.html#words-over-time"><i class="fa fa-check"></i><b>9.6.1</b> Words over time</a></li>
<li class="chapter" data-level="9.6.2" data-path="term-frequencies.html"><a href="term-frequencies.html#chart-several-words-over-time"><i class="fa fa-check"></i><b>9.6.2</b> Chart several words over time</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="term-frequencies.html"><a href="term-frequencies.html#further-reading"><i class="fa fa-check"></i><b>9.7</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="calculating-tf-idf-scores-with-tidytext.html"><a href="calculating-tf-idf-scores-with-tidytext.html"><i class="fa fa-check"></i><b>10</b> Calculating tf-idf Scores with Tidytext</a></li>
<li class="chapter" data-level="11" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html"><i class="fa fa-check"></i><b>11</b> Sentiment analysis</a><ul>
<li class="chapter" data-level="11.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#install-and-load-relevant-packages"><i class="fa fa-check"></i><b>11.1</b> Install and load relevant packages</a></li>
<li class="chapter" data-level="11.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#fetch-sentiment-data"><i class="fa fa-check"></i><b>11.2</b> Fetch sentiment data</a><ul>
<li class="chapter" data-level="11.2.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#afinn-dataset"><i class="fa fa-check"></i><b>11.2.1</b> Afinn dataset</a></li>
<li class="chapter" data-level="11.2.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#bing-dataset"><i class="fa fa-check"></i><b>11.2.2</b> Bing dataset</a></li>
<li class="chapter" data-level="11.2.3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#loughran-dataset"><i class="fa fa-check"></i><b>11.2.3</b> Loughran dataset</a></li>
<li class="chapter" data-level="11.2.4" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#nrc-dataset"><i class="fa fa-check"></i><b>11.2.4</b> NRC dataset</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#load-the-tokenised-news-sample"><i class="fa fa-check"></i><b>11.3</b> Load the tokenised news sample</a></li>
<li class="chapter" data-level="11.4" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#charting-changes-in-sentiment-over-time"><i class="fa fa-check"></i><b>11.4</b> Charting Changes in Sentiment Over Time</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="topic-modelling.html"><a href="topic-modelling.html"><i class="fa fa-check"></i><b>12</b> Topic modelling</a><ul>
<li class="chapter" data-level="12.1" data-path="topic-modelling.html"><a href="topic-modelling.html#topic-modelling-with-the-library-topicmodels"><i class="fa fa-check"></i><b>12.1</b> Topic modelling with the library ‘topicmodels’</a></li>
<li class="chapter" data-level="12.2" data-path="topic-modelling.html"><a href="topic-modelling.html#load-the-tokenised-dataframe"><i class="fa fa-check"></i><b>12.2</b> Load the tokenised dataframe</a></li>
<li class="chapter" data-level="12.3" data-path="topic-modelling.html"><a href="topic-modelling.html#create-a-dataframe-of-word-counts-with-tf_idf-scores"><i class="fa fa-check"></i><b>12.3</b> Create a dataframe of word counts with tf_idf scores</a></li>
<li class="chapter" data-level="12.4" data-path="topic-modelling.html"><a href="topic-modelling.html#make-a-document-term-matrix"><i class="fa fa-check"></i><b>12.4</b> Make a ‘document term matrix’</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html"><i class="fa fa-check"></i><b>13</b> Detecting text reuse in newspaper articles.</a><ul>
<li class="chapter" data-level="13.1" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#turn-the-newspaper-sample-into-a-bunch-of-text-documents-one-per-article"><i class="fa fa-check"></i><b>13.1</b> Turn the newspaper sample into a bunch of text documents, one per article</a><ul>
<li class="chapter" data-level="13.1.1" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#load-the-dataframe-and-preprocess"><i class="fa fa-check"></i><b>13.1.1</b> Load the dataframe and preprocess</a></li>
<li class="chapter" data-level="13.1.2" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#make-a-text-file-from-each-article"><i class="fa fa-check"></i><b>13.1.2</b> Make a text file from each article</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#load-the-files-as-a-textreusecorpus"><i class="fa fa-check"></i><b>13.2</b> Load the files as a TextReuseCorpus</a><ul>
<li class="chapter" data-level="13.2.1" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#generate-a-minhash"><i class="fa fa-check"></i><b>13.2.1</b> Generate a minhash</a></li>
<li class="chapter" data-level="13.2.2" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#create-the-textreusecorpus"><i class="fa fa-check"></i><b>13.2.2</b> Create the TextReuseCorpus</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#further-reading-1"><i class="fa fa-check"></i><b>13.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="further-reading-2.html"><a href="further-reading-2.html"><i class="fa fa-check"></i><b>14</b> Further reading</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A short guide to using British Library Newspaper Data, using R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="detecting-text-reuse-in-newspaper-articles." class="section level1">
<h1><span class="header-section-number">13</span> Detecting text reuse in newspaper articles.</h1>
<p>19th century newspapers shared text all the time. Sometimes this took the form of credited reports from other titles. For much of the century, newspapers paid the post office to give them a copy of all other titles. Official reused dispatches were not the only way text was reused: advertisements, of course, were placed in multiple titles at the same time, and editors were happy to use snippets, jokes, and so forth</p>
<p>Detecting the extent of this reuse is a great use of digital tools. R has a library, <em>textreuse</em>, which allows you to do this reasonably simply. It was intended to be used for plagiarism detection and to find duplicated documents, but it can also be repurposed to find shared articles.</p>
<p>Some of the most inspiring news data projects at the moment are looking at text reuse. The <em>Oceanic Exchanges</em> project is a multi-partner project using various methods to detect this overlap. This methods paper is really interesting, and used a similar starting point, though it then does an extra step of calculating ‘local alignment’ with each candidate pair, to improve the accuracy.<span class="citation"><a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a></span></p>
<p>Melodee Beals’s <a href="http://scissorsandpaste.net"><em>Scissors and Paste</em></a> project, at Loughborough and also part of <em>Oceanic Exchanges</em>, also looks at text reuse in 19th century British newspapers. <a href="http://comhis.fi/clusters">Another project</a>, looking at Finnish newspapers, used a technique usually used to detect protein strains to find clusters of text reuse on particularly inaccurate OCR.<span class="citation"><a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></span></p>
<p>The steps are the following:</p>
<ul>
<li><p>Turn the newspaper sample into a bunch of text documents, one per article</p></li>
<li><p>Load these into R as a special forat called a TextReuseCorpus.</p></li>
<li><p>Divide the text into a series of overlapping sequences of words, known as n-grams.</p></li>
<li><p>‘Hash’ the n-grams - each one is given a numerical code, which is much less memory-hungry. Randomly select 200 of these hashes to represent each document.</p></li>
<li><p>Use a local sensitivity hashing algorithm (I’ll explain a bit below) to generate a list of potential candidates for text reuse</p></li>
<li><p>Calculate the similarity scores for these candidates</p></li>
<li><p>Calculate the local alignment of the pairs to find out exactly which bits overlap</p></li>
</ul>
<p>To set some expectations: this tutorial uses a small sample dataset of one title over a period of months, and unsurprisingly, there’s not really any text re-use. A larger corpus over a short time period, with a number of titles, would probably give more interesting results.</p>
<p>Also, these techniques were developed with modern text in mind, and so the results will be limited by the accurary of the OCR, but by setting the parameters reasonably loose we might be able to mitigate for this.</p>
<p><a href="http://matthewcasperson.blogspot.com/2013/11/minhash-for-dummies.html" class="uri">http://matthewcasperson.blogspot.com/2013/11/minhash-for-dummies.html</a></p>
<p><a href="http://infolab.stanford.edu/~ullman/mmds/ch3.pdf" class="uri">http://infolab.stanford.edu/~ullman/mmds/ch3.pdf</a></p>
<div id="turn-the-newspaper-sample-into-a-bunch-of-text-documents-one-per-article" class="section level2">
<h2><span class="header-section-number">13.1</span> Turn the newspaper sample into a bunch of text documents, one per article</h2>
<p>Load libaries: the usual suspect, tidyverse, and also the package ‘textreuse’. If it’s not installed, you’ll need to do so using <code>install.packages('textreuse')</code></p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb192-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb192-2" data-line-number="2"><span class="kw">library</span>(textreuse)</a></code></pre></div>
<pre><code>## 
## Attaching package: &#39;textreuse&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:readr&#39;:
## 
##     tokenize</code></pre>
<div id="load-the-dataframe-and-preprocess" class="section level3">
<h3><span class="header-section-number">13.1.1</span> Load the dataframe and preprocess</h3>
<p>In the <em>extract text</em> chapter <a href="#label"><strong>??</strong></a>, you created a dataframe, with one row per article. The first step is to reload that dataframe into memory, and do some minor preprocessing.</p>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb195-1" data-line-number="1"><span class="kw">load</span>(<span class="st">&#39;news_sample_dataframe&#39;</span>)</a></code></pre></div>
<p>Make a more useful code to use as an article ID.
First use <code>str_pad()</code> to add leading zeros up to a maximum of three digits.</p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb196-1" data-line-number="1">news_sample_dataframe<span class="op">$</span>article_code =<span class="st"> </span><span class="kw">str_pad</span>(news_sample_dataframe<span class="op">$</span>article_code, </a>
<a class="sourceLine" id="cb196-2" data-line-number="2">                                             <span class="dt">width =</span> <span class="dv">3</span>, </a>
<a class="sourceLine" id="cb196-3" data-line-number="3">                                             <span class="dt">pad =</span> <span class="st">&#39;0&#39;</span>)</a></code></pre></div>
<p>Use <code>paste0()</code> to add the prefix ‘article’ to this number.</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb197-1" data-line-number="1">news_sample_dataframe<span class="op">$</span>article_code =<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&#39;article_&#39;</span>,</a>
<a class="sourceLine" id="cb197-2" data-line-number="2">                                            news_sample_dataframe<span class="op">$</span>article_code)</a></code></pre></div>
<p>Unfortunately, this is a very slow process, and we have 170,000 articles to compare. For the purposes of this demonstration, use <code>sample_n</code> to make a sample. The only problem is that it makes the code unreproducible. It might be better to sample based on a limited time period.</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb198-1" data-line-number="1">sample_for_text_reuse =<span class="st"> </span>news_sample_dataframe <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sample_n</span>(<span class="dv">10000</span>)</a></code></pre></div>
</div>
<div id="make-a-text-file-from-each-article" class="section level3">
<h3><span class="header-section-number">13.1.2</span> Make a text file from each article</h3>
<p>This is a very simple function - it says, for each row in the news_sample_dataframe, write the third cell (which is where the text of the article is stored), using a function from a library called data.table called fwrite(), store it in a folder called textfiles/, and make a filename from the article code concatenated with ‘.txt’.</p>
<p>R won’t let you create a folder, so create an empty folder first, in the project directory, called <code>textfiles</code></p>
<p>Now you should have a folder in the project folder called textfiles, with a small text document for each article inside. This is a LOT of text documents, so your computer might complain.</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb199-1" data-line-number="1"><span class="kw">library</span>(data.table)</a>
<a class="sourceLine" id="cb199-2" data-line-number="2"></a>
<a class="sourceLine" id="cb199-3" data-line-number="3"></a>
<a class="sourceLine" id="cb199-4" data-line-number="4"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(sample_for_text_reuse)){</a>
<a class="sourceLine" id="cb199-5" data-line-number="5">    </a>
<a class="sourceLine" id="cb199-6" data-line-number="6">    </a>
<a class="sourceLine" id="cb199-7" data-line-number="7">  filename =<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;textfiles/&quot;</span>, news_sample_dataframe[i,<span class="dv">1</span>],<span class="st">&quot;.txt&quot;</span>)</a>
<a class="sourceLine" id="cb199-8" data-line-number="8">  </a>
<a class="sourceLine" id="cb199-9" data-line-number="9">  <span class="kw">fwrite</span>(news_sample_dataframe[i,<span class="dv">3</span>], <span class="dt">file =</span> filename)</a>
<a class="sourceLine" id="cb199-10" data-line-number="10">}</a></code></pre></div>
</div>
</div>
<div id="load-the-files-as-a-textreusecorpus" class="section level2">
<h2><span class="header-section-number">13.2</span> Load the files as a TextReuseCorpus</h2>
<div id="generate-a-minhash" class="section level3">
<h3><span class="header-section-number">13.2.1</span> Generate a minhash</h3>
<p>Use the function minhash_generator() to specify the number of minhashes you want to represent each document. Set the random seed to make it reproducible.</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb200-1" data-line-number="1">minhash &lt;-<span class="st"> </span><span class="kw">minhash_generator</span>(<span class="dt">n =</span> <span class="dv">400</span>, <span class="dt">seed =</span> <span class="dv">1234</span>)</a></code></pre></div>
</div>
<div id="create-the-textreusecorpus" class="section level3">
<h3><span class="header-section-number">13.2.2</span> Create the TextReuseCorpus</h3>
<p><code>TextReuseCorpus()</code> takes a number of arguments. Going through each in turn:</p>
<p><em>dir =</em> is the directory where all the text files are stored.</p>
<p><em>tokenizer</em> is the function which tokenises the text. Here we’ve used tokenize_ngrams, but it could also be tokenize words. You could build your own: for example, if you thought that comparing similar characters in small sequences would help to detect text reuse, you could use that to compare the documents.</p>
<p><em>n</em> is the number of tokens in the ngram tokeniser. Setting it at 4 turns the following sentence:</p>
<blockquote>
<p>Here we’ve used tokenize_ngrams, but it could also be tokenize words</p>
</blockquote>
<p>into:</p>
<p>Here we’ve used tokenize_ngrams
we’ve used tokenize_ngrams but
used tokenize_ngrams but it
tokenize_ngrams but it could
but it could also
it could also be
could also be tokenize
also be tokenize words</p>
<p><em>minhash_func =</em> is the parameters set using <code>minhash_generator()</code> above</p>
<p><em>keep_tokens =</em> Whether or not you keep the actual tokens, or just the hashes. There’s no real point keeping the tokens as we use the hashes to make the comparisons. This function will take a long time to run with a large number of documents.</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb201-1" data-line-number="1">reusecorpus &lt;-<span class="st"> </span><span class="kw">TextReuseCorpus</span>(<span class="dt">dir =</span> <span class="st">&quot;textfiles/&quot;</span>, </a>
<a class="sourceLine" id="cb201-2" data-line-number="2">                               <span class="dt">tokenizer =</span> tokenize_ngrams, </a>
<a class="sourceLine" id="cb201-3" data-line-number="3">                               <span class="dt">n =</span> <span class="dv">3</span>,</a>
<a class="sourceLine" id="cb201-4" data-line-number="4">                          <span class="dt">minhash_func =</span> minhash, </a>
<a class="sourceLine" id="cb201-5" data-line-number="5">                          <span class="dt">keep_tokens =</span> <span class="ot">FALSE</span>, </a>
<a class="sourceLine" id="cb201-6" data-line-number="6">                          <span class="dt">progress =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p>Now each document is represented by a series of hashes, which are substitutes for small sequences of text. For example, this is the first ten minhashes for the first article:</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb202-1" data-line-number="1"><span class="kw">head</span>(<span class="kw">minhashes</span>(reusecorpus[[<span class="dv">1</span>]]),<span class="dv">10</span>)</a></code></pre></div>
<pre><code>##  [1] -1212289576 -1296295640 -1240828060 -1301884635  -241702409 -1910996997
##  [7] -1463281870 -1859245701 -2022216262 -1370034986</code></pre>
<p>At this point, you could compare any document’s sequences of hashes to any other, and get its ‘Jacquard Similarity’ score, which counts the number of shared hashes in the documents. The more shared hashes, the higher the similarity.</p>
<p>However, it would be very difficult, even for a computer, to use this to compare every document to every other in a corpus. A Local Sensitivity Hashing algorithm is used to solve this problem. This groups the representations together, and finds pairs of documents that should be compared for similarity.</p>
<blockquote>
<p>LSH breaks the minhashes into a series of bands comprised of rows. For example, 200 minhashes might broken into 50 bands of 4 rows each. Each band is hashed to a bucket. If two documents have the exact same minhashes in a band, they will be hashed to the same bucket, and so will be considered candidate pairs. Each pair of documents has as many chances to be considered a candidate as their are bands, and the fewer rows there are in each band, the more likely it is that each document will match another. (<a href="https://cran.r-project.org/web/packages/textreuse/vignettes/textreuse-minhash.html" class="uri">https://cran.r-project.org/web/packages/textreuse/vignettes/textreuse-minhash.html</a>)</p>
</blockquote>
<p>First create the buckets. You can try other values for the bands.</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb204-1" data-line-number="1">buckets &lt;-<span class="st"> </span><span class="kw">lsh</span>(reusecorpus, <span class="dt">bands =</span> <span class="dv">80</span>, <span class="dt">progress =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |                                                                      |   1%
  |                                                                            
  |=                                                                     |   1%
  |                                                                            
  |=                                                                     |   2%
  |                                                                            
  |==                                                                    |   2%
  |                                                                            
  |==                                                                    |   3%
  |                                                                            
  |==                                                                    |   4%
  |                                                                            
  |===                                                                   |   4%
  |                                                                            
  |===                                                                   |   5%
  |                                                                            
  |====                                                                  |   5%
  |                                                                            
  |====                                                                  |   6%
  |                                                                            
  |=====                                                                 |   6%
  |                                                                            
  |=====                                                                 |   7%
  |                                                                            
  |=====                                                                 |   8%
  |                                                                            
  |======                                                                |   8%
  |                                                                            
  |======                                                                |   9%
  |                                                                            
  |=======                                                               |   9%
  |                                                                            
  |=======                                                               |  10%
  |                                                                            
  |=======                                                               |  11%
  |                                                                            
  |========                                                              |  11%
  |                                                                            
  |========                                                              |  12%
  |                                                                            
  |=========                                                             |  12%
  |                                                                            
  |=========                                                             |  13%
  |                                                                            
  |=========                                                             |  14%
  |                                                                            
  |==========                                                            |  14%
  |                                                                            
  |==========                                                            |  15%
  |                                                                            
  |===========                                                           |  15%
  |                                                                            
  |===========                                                           |  16%
  |                                                                            
  |============                                                          |  16%
  |                                                                            
  |============                                                          |  17%
  |                                                                            
  |============                                                          |  18%
  |                                                                            
  |=============                                                         |  18%
  |                                                                            
  |=============                                                         |  19%
  |                                                                            
  |==============                                                        |  19%
  |                                                                            
  |==============                                                        |  20%
  |                                                                            
  |==============                                                        |  21%
  |                                                                            
  |===============                                                       |  21%
  |                                                                            
  |===============                                                       |  22%
  |                                                                            
  |================                                                      |  22%
  |                                                                            
  |================                                                      |  23%
  |                                                                            
  |================                                                      |  24%
  |                                                                            
  |=================                                                     |  24%
  |                                                                            
  |=================                                                     |  25%
  |                                                                            
  |==================                                                    |  25%
  |                                                                            
  |==================                                                    |  26%
  |                                                                            
  |===================                                                   |  26%
  |                                                                            
  |===================                                                   |  27%
  |                                                                            
  |===================                                                   |  28%
  |                                                                            
  |====================                                                  |  28%
  |                                                                            
  |====================                                                  |  29%
  |                                                                            
  |=====================                                                 |  29%
  |                                                                            
  |=====================                                                 |  30%
  |                                                                            
  |=====================                                                 |  31%
  |                                                                            
  |======================                                                |  31%
  |                                                                            
  |======================                                                |  32%
  |                                                                            
  |=======================                                               |  32%
  |                                                                            
  |=======================                                               |  33%
  |                                                                            
  |=======================                                               |  34%
  |                                                                            
  |========================                                              |  34%
  |                                                                            
  |========================                                              |  35%
  |                                                                            
  |=========================                                             |  35%
  |                                                                            
  |=========================                                             |  36%
  |                                                                            
  |==========================                                            |  36%
  |                                                                            
  |==========================                                            |  37%
  |                                                                            
  |==========================                                            |  38%
  |                                                                            
  |===========================                                           |  38%
  |                                                                            
  |===========================                                           |  39%
  |                                                                            
  |============================                                          |  39%
  |                                                                            
  |============================                                          |  40%
  |                                                                            
  |============================                                          |  41%
  |                                                                            
  |=============================                                         |  41%
  |                                                                            
  |=============================                                         |  42%
  |                                                                            
  |==============================                                        |  42%
  |                                                                            
  |==============================                                        |  43%
  |                                                                            
  |==============================                                        |  44%
  |                                                                            
  |===============================                                       |  44%
  |                                                                            
  |===============================                                       |  45%
  |                                                                            
  |================================                                      |  45%
  |                                                                            
  |================================                                      |  46%
  |                                                                            
  |=================================                                     |  46%
  |                                                                            
  |=================================                                     |  47%
  |                                                                            
  |=================================                                     |  48%
  |                                                                            
  |==================================                                    |  48%
  |                                                                            
  |==================================                                    |  49%
  |                                                                            
  |===================================                                   |  49%
  |                                                                            
  |===================================                                   |  50%
  |                                                                            
  |===================================                                   |  51%
  |                                                                            
  |====================================                                  |  51%
  |                                                                            
  |====================================                                  |  52%
  |                                                                            
  |=====================================                                 |  52%
  |                                                                            
  |=====================================                                 |  53%
  |                                                                            
  |=====================================                                 |  54%
  |                                                                            
  |======================================                                |  54%
  |                                                                            
  |======================================                                |  55%
  |                                                                            
  |=======================================                               |  55%
  |                                                                            
  |=======================================                               |  56%
  |                                                                            
  |========================================                              |  56%
  |                                                                            
  |========================================                              |  57%
  |                                                                            
  |========================================                              |  58%
  |                                                                            
  |=========================================                             |  58%
  |                                                                            
  |=========================================                             |  59%
  |                                                                            
  |==========================================                            |  59%
  |                                                                            
  |==========================================                            |  60%
  |                                                                            
  |==========================================                            |  61%
  |                                                                            
  |===========================================                           |  61%
  |                                                                            
  |===========================================                           |  62%
  |                                                                            
  |============================================                          |  62%
  |                                                                            
  |============================================                          |  63%
  |                                                                            
  |============================================                          |  64%
  |                                                                            
  |=============================================                         |  64%
  |                                                                            
  |=============================================                         |  65%
  |                                                                            
  |==============================================                        |  65%
  |                                                                            
  |==============================================                        |  66%
  |                                                                            
  |===============================================                       |  66%
  |                                                                            
  |===============================================                       |  67%
  |                                                                            
  |===============================================                       |  68%
  |                                                                            
  |================================================                      |  68%
  |                                                                            
  |================================================                      |  69%
  |                                                                            
  |=================================================                     |  69%
  |                                                                            
  |=================================================                     |  70%
  |                                                                            
  |=================================================                     |  71%
  |                                                                            
  |==================================================                    |  71%
  |                                                                            
  |==================================================                    |  72%
  |                                                                            
  |===================================================                   |  72%
  |                                                                            
  |===================================================                   |  73%
  |                                                                            
  |===================================================                   |  74%
  |                                                                            
  |====================================================                  |  74%
  |                                                                            
  |====================================================                  |  75%
  |                                                                            
  |=====================================================                 |  75%
  |                                                                            
  |=====================================================                 |  76%
  |                                                                            
  |======================================================                |  76%
  |                                                                            
  |======================================================                |  77%
  |                                                                            
  |======================================================                |  78%
  |                                                                            
  |=======================================================               |  78%
  |                                                                            
  |=======================================================               |  79%
  |                                                                            
  |========================================================              |  79%
  |                                                                            
  |========================================================              |  80%
  |                                                                            
  |========================================================              |  81%
  |                                                                            
  |=========================================================             |  81%
  |                                                                            
  |=========================================================             |  82%
  |                                                                            
  |==========================================================            |  82%
  |                                                                            
  |==========================================================            |  83%
  |                                                                            
  |==========================================================            |  84%
  |                                                                            
  |===========================================================           |  84%
  |                                                                            
  |===========================================================           |  85%
  |                                                                            
  |============================================================          |  85%
  |                                                                            
  |============================================================          |  86%
  |                                                                            
  |=============================================================         |  86%
  |                                                                            
  |=============================================================         |  87%
  |                                                                            
  |=============================================================         |  88%
  |                                                                            
  |==============================================================        |  88%
  |                                                                            
  |==============================================================        |  89%
  |                                                                            
  |===============================================================       |  89%
  |                                                                            
  |===============================================================       |  90%
  |                                                                            
  |===============================================================       |  91%
  |                                                                            
  |================================================================      |  91%
  |                                                                            
  |================================================================      |  92%
  |                                                                            
  |=================================================================     |  92%
  |                                                                            
  |=================================================================     |  93%
  |                                                                            
  |=================================================================     |  94%
  |                                                                            
  |==================================================================    |  94%
  |                                                                            
  |==================================================================    |  95%
  |                                                                            
  |===================================================================   |  95%
  |                                                                            
  |===================================================================   |  96%
  |                                                                            
  |====================================================================  |  96%
  |                                                                            
  |====================================================================  |  97%
  |                                                                            
  |====================================================================  |  98%
  |                                                                            
  |===================================================================== |  98%
  |                                                                            
  |===================================================================== |  99%
  |                                                                            
  |======================================================================|  99%
  |                                                                            
  |======================================================================| 100%</code></pre>
<p>Next, use <code>lsh_candidates()</code> to compare each bucket, and generate a list of candidates.</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb206-1" data-line-number="1">candidates &lt;-<span class="st"> </span><span class="kw">lsh_candidates</span>(buckets)</a></code></pre></div>
<p>Next we go back to the full corpus, and calculate the similarity score for these pairs, using <code>lsh_compare()</code>. The first argument is the candidates, the second is the full corpus, the third is the method (other similarity functions could be used).</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb207-1" data-line-number="1">jacsimilarity_both =<span class="st"> </span><span class="kw">lsh_compare</span>(candidates, </a>
<a class="sourceLine" id="cb207-2" data-line-number="2">                                 reusecorpus, </a>
<a class="sourceLine" id="cb207-3" data-line-number="3">                                 jaccard_similarity, </a>
<a class="sourceLine" id="cb207-4" data-line-number="4">                                 <span class="dt">progress =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb207-5" data-line-number="5"><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(score))</a>
<a class="sourceLine" id="cb207-6" data-line-number="6"></a>
<a class="sourceLine" id="cb207-7" data-line-number="7">jacsimilarity_both</a></code></pre></div>
<pre><code>## # A tibble: 7,423 x 3
##    a            b            score
##    &lt;chr&gt;        &lt;chr&gt;        &lt;dbl&gt;
##  1 article_1053 article_1107     1
##  2 article_1083 article_3348     1
##  3 article_1110 article_1134     1
##  4 article_1110 article_1536     1
##  5 article_1110 article_1566     1
##  6 article_1110 article_1689     1
##  7 article_1110 article_1766     1
##  8 article_1110 article_1827     1
##  9 article_1110 article_1836     1
## 10 article_1110 article_1908     1
## # … with 7,413 more rows</code></pre>
<p>It returns a similarity score for each pair: The first pair have a 25% overlap, and the second a much smaller number.</p>
<p>The last thing is to join up the article codes to the full text dataset, and actually see what pairs have been detected. This is done using two <code>left_join()</code> commands, one for a and one for b. Also select just the relevant columns, and filter out those with a perfect score as they are very likely to be artefacts rather than full articles, and filter out those where both documents are from the same issue.</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb209-1" data-line-number="1">matchedtexts =<span class="st"> </span>jacsimilarity_both <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb209-2" data-line-number="2"><span class="st">  </span><span class="kw">left_join</span>(news_sample_dataframe, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&#39;a&#39;</span> =<span class="st"> &#39;article_code&#39;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb209-3" data-line-number="3"><span class="st">  </span><span class="kw">left_join</span>(news_sample_dataframe, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&#39;b&#39;</span> =<span class="st"> &#39;article_code&#39;</span>))<span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb209-4" data-line-number="4"><span class="st">  </span><span class="kw">select</span>(a,b,score, text.x, text.y, title.x, title.y, full_date.x, full_date.y)</a>
<a class="sourceLine" id="cb209-5" data-line-number="5"></a>
<a class="sourceLine" id="cb209-6" data-line-number="6">matchedtexts =<span class="st"> </span>matchedtexts <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(score<span class="op">&lt;</span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(full_date.x <span class="op">!=</span><span class="st"> </span>full_date.y)</a></code></pre></div>
<p>To check the specific overlap of two documnets, use another function from textreuse to check the ‘local alignment’. This is like comparing two documents in Microsoft Word: it finds the bit of the text with the most overlap, and it points out where in this overlap there are different words, replacing them with ######</p>
<p>First turn the text in each cell into a string:</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb210-1" data-line-number="1">a =<span class="st"> </span><span class="kw">paste</span>(matchedtexts<span class="op">$</span>text.x[<span class="dv">3</span>], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>, <span class="dt">collapse=</span><span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb210-2" data-line-number="2"></a>
<a class="sourceLine" id="cb210-3" data-line-number="3">b =<span class="st">  </span><span class="kw">paste</span>(matchedtexts<span class="op">$</span>text.y[<span class="dv">3</span>], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>, <span class="dt">collapse=</span><span class="st">&quot;&quot;</span>)</a></code></pre></div>
<p>Call the <code>align_local()</code> function, giving it the two strings to compare.</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb211-1" data-line-number="1"><span class="kw">align_local</span>(a, b)</a></code></pre></div>
<pre><code>## TextReuse alignment
## Alignment score: 165 
## Document A:
## TO CORRESPONDENTS No notice can be taken of anonymous communications
## Whatever is intended for insertion must be authenticated by the name
## and address of the writer not necessarily for publication ############
## but as a guarrantee of his good faith We cannot undertake to return
## rejected communications All communications Books for Review etc to be
## for forwarded warded forwarded to the Editor must be addressed to the
## Publisher CHARLES WILLMER and those from London may be sent to the care
## of Messrs Simpkin Marshall and Co
## 
## Document B:
## TO CORRESPONDENTS No notice can be taken of anonymous communications
## Whatever is intended for insertion must be authenticated by the name
## and address of the writer not necessarily for ########### _publication
## but as a guarrantee of his good faith We cannot undertake to return
## rejected communications All communications Books for Review etc to be
## for forwarded warded forwarded to the Editor must be addressed to the
## Publisher CHARLES WILLMER and those from London may be sent to the care
## of Messrs Simpkin Marshall and Co</code></pre>
<p>Unsurprisingly, the pairs of documents are nearly all advertisements.</p>
<p>This is very much a beginning, but I hope you can see the potential. It’s worth noting that the article segmentation in these newspapers might actually work against the process, because it often lumps multiple articles into one document. Consequently, the software won’t find potential matches if there’s too much other non-matching same text in the same document.</p>
<p>A potential work-around would be to split the document into chunks of text, and compare these chunks. The chunks could be joined back to the full articles, and using local alignment, the specific bits that overlapped could be found.</p>
</div>
</div>
<div id="further-reading-1" class="section level2">
<h2><span class="header-section-number">13.3</span> Further reading</h2>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="15">
<li id="fn15"><p>David A. Smith, Ryan Cordell, and Abby Mullen, ‘Computational Methods for Uncovering Reprinted Texts in Antebellum Newspapers’, <em>American Literary History</em>, 27.3 (2015), E1–E15 &lt;<a href="https://doi.org/10.1093/alh/ajv029">https://doi.org/10.1093/alh/ajv029</a>&gt;.<a href="detecting-text-reuse-in-newspaper-articles-.html#fnref15" class="footnote-back">↩</a></p></li>
<li id="fn16"><p><span class="citeproc-not-found" data-reference-id="inproceedings-salmi"><strong>???</strong></span>, <span class="citation">@inproceedings-blast</span>.<a href="detecting-text-reuse-in-newspaper-articles-.html#fnref16" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="topic-modelling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="further-reading-2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
